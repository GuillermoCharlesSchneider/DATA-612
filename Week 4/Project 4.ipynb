{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "0243918a-7f59-4c74-b696-501ccd979254",
      "cell_type": "code",
      "source": "#imports\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "id": "b21f8ebc-7c73-4716-bf2a-86931736852e",
      "cell_type": "markdown",
      "source": "# DATA 612 Project 4 | Accuracy and Beyond ",
      "metadata": {}
    },
    {
      "id": "21d45b3d-64c9-4c9f-b238-e2575a2f382e",
      "cell_type": "markdown",
      "source": "### Choose a different dataset (MovieLens) to work with from your previous projects",
      "metadata": {}
    },
    {
      "id": "3f506eaa-3a4f-4228-ac51-9254a2d35b84",
      "cell_type": "markdown",
      "source": "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.",
      "metadata": {}
    },
    {
      "id": "5b9553e9-9ad5-4ed8-81c0-2fddf4625d69",
      "cell_type": "code",
      "source": "original_movies_df = pd.read_csv('movies.csv')\noriginal_ratings_df = pd.read_csv('ratings.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "8dcb94f7-4dd6-4ab0-9b73-eb4cc6d16af7",
      "cell_type": "code",
      "source": "original_movies_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      movieId                                      title  \\\n0           1                           Toy Story (1995)   \n1           2                             Jumanji (1995)   \n2           3                    Grumpier Old Men (1995)   \n3           4                   Waiting to Exhale (1995)   \n4           5         Father of the Bride Part II (1995)   \n...       ...                                        ...   \n9737   193581  Black Butler: Book of the Atlantic (2017)   \n9738   193583               No Game No Life: Zero (2017)   \n9739   193585                               Flint (2017)   \n9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n\n                                           genres  \n0     Adventure|Animation|Children|Comedy|Fantasy  \n1                      Adventure|Children|Fantasy  \n2                                  Comedy|Romance  \n3                            Comedy|Drama|Romance  \n4                                          Comedy  \n...                                           ...  \n9737              Action|Animation|Comedy|Fantasy  \n9738                     Animation|Comedy|Fantasy  \n9739                                        Drama  \n9740                             Action|Animation  \n9741                                       Comedy  \n\n[9742 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9737</th>\n      <td>193581</td>\n      <td>Black Butler: Book of the Atlantic (2017)</td>\n      <td>Action|Animation|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>9738</th>\n      <td>193583</td>\n      <td>No Game No Life: Zero (2017)</td>\n      <td>Animation|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>9739</th>\n      <td>193585</td>\n      <td>Flint (2017)</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>9740</th>\n      <td>193587</td>\n      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n      <td>Action|Animation</td>\n    </tr>\n    <tr>\n      <th>9741</th>\n      <td>193609</td>\n      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n<p>9742 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "id": "ae037305-d0c9-497d-a2e2-e033b6a7132b",
      "cell_type": "code",
      "source": "original_ratings_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        userId  movieId  rating   timestamp\n0            1        1     4.0   964982703\n1            1        3     4.0   964981247\n2            1        6     4.0   964982224\n3            1       47     5.0   964983815\n4            1       50     5.0   964982931\n...        ...      ...     ...         ...\n100831     610   166534     4.0  1493848402\n100832     610   168248     5.0  1493850091\n100833     610   168250     5.0  1494273047\n100834     610   168252     5.0  1493846352\n100835     610   170875     3.0  1493846415\n\n[100836 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100831</th>\n      <td>610</td>\n      <td>166534</td>\n      <td>4.0</td>\n      <td>1493848402</td>\n    </tr>\n    <tr>\n      <th>100832</th>\n      <td>610</td>\n      <td>168248</td>\n      <td>5.0</td>\n      <td>1493850091</td>\n    </tr>\n    <tr>\n      <th>100833</th>\n      <td>610</td>\n      <td>168250</td>\n      <td>5.0</td>\n      <td>1494273047</td>\n    </tr>\n    <tr>\n      <th>100834</th>\n      <td>610</td>\n      <td>168252</td>\n      <td>5.0</td>\n      <td>1493846352</td>\n    </tr>\n    <tr>\n      <th>100835</th>\n      <td>610</td>\n      <td>170875</td>\n      <td>3.0</td>\n      <td>1493846415</td>\n    </tr>\n  </tbody>\n</table>\n<p>100836 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "id": "108cfd6e-5ff3-438d-b8cb-efad112180ab",
      "cell_type": "code",
      "source": "# Convert to user-item matrix\nuser_item_matrix = original_ratings_df.pivot(index='userId', columns='movieId', values='rating')\n\n# Optional: Fill missing values (e.g., with 0 or NaN)\nuser_item_matrix = user_item_matrix.fillna(0)\nuser_item_matrix",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "movieId  1       2       3       4       5       6       7       8       \\\nuserId                                                                    \n1           4.0     0.0     4.0     0.0     0.0     4.0     0.0     0.0   \n2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n5           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n...         ...     ...     ...     ...     ...     ...     ...     ...   \n606         2.5     0.0     0.0     0.0     0.0     0.0     2.5     0.0   \n607         4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n608         2.5     2.0     2.0     0.0     0.0     0.0     0.0     0.0   \n609         3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n610         5.0     0.0     0.0     0.0     0.0     5.0     0.0     0.0   \n\nmovieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\nuserId                   ...                                                   \n1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n2           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n3           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n4           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n5           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n606         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n607         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n608         0.0     4.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n609         0.0     4.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n610         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n\nmovieId  193583  193585  193587  193609  \nuserId                                   \n1           0.0     0.0     0.0     0.0  \n2           0.0     0.0     0.0     0.0  \n3           0.0     0.0     0.0     0.0  \n4           0.0     0.0     0.0     0.0  \n5           0.0     0.0     0.0     0.0  \n...         ...     ...     ...     ...  \n606         0.0     0.0     0.0     0.0  \n607         0.0     0.0     0.0     0.0  \n608         0.0     0.0     0.0     0.0  \n609         0.0     0.0     0.0     0.0  \n610         0.0     0.0     0.0     0.0  \n\n[610 rows x 9724 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>movieId</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>193565</th>\n      <th>193567</th>\n      <th>193571</th>\n      <th>193573</th>\n      <th>193579</th>\n      <th>193581</th>\n      <th>193583</th>\n      <th>193585</th>\n      <th>193587</th>\n      <th>193609</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>610 rows × 9724 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "id": "dfbd1ba5-a56f-444b-850e-89856fb7765e",
      "cell_type": "markdown",
      "source": "### 1. Compare the accuracy of at least two recommender system algorithms against your offline data. Choose two recommenders, then pick a metric. you can look at RMSE and MEA, but pick something recommender specific like novelty, diversity, serendipity. ",
      "metadata": {}
    },
    {
      "id": "bcc4bf99-a2d1-48b5-89ae-961829c85f14",
      "cell_type": "markdown",
      "source": "### Recommender 1: User-Based Collaborative Filtering (UBCF)",
      "metadata": {}
    },
    {
      "id": "bafa62e4-c762-4d00-b913-4320944d8ceb",
      "cell_type": "markdown",
      "source": "#### User-Based Collaborative Filtering (UBCF) recommender system using cosine similarity between users. To recommend items to a target user by:\n\n- Finding similar users (via cosine similarity)\n\n- Aggregating their ratings for items the target user hasn't seen\n\n- Predicting how much the target user would like those unseen items\n\n- Returning the top recommendation",
      "metadata": {}
    },
    {
      "id": "77dc3c13-d100-4f9f-9213-8b310d08b053",
      "cell_type": "code",
      "source": "# Compute cosine similarity between users\nuser_similarity = cosine_similarity(user_item_matrix)\nuser_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n\n# Predict ratings for a target user\ndef predict_ratings_user_based(target_user_id):\n    similar_users = user_similarity_df[target_user_id].sort_values(ascending=False)[:]\n    sim_scores = similar_users.values\n    sim_users = similar_users.index\n\n    target_user_ratings = user_item_matrix.loc[target_user_id]\n    predicted_ratings = {}\n\n    for item in user_item_matrix.columns:\n        if target_user_ratings[item] == 0:  # Only predict for unseen items\n            numerator = 0\n            denominator = 0\n            for i, sim_user in enumerate(sim_users):\n                rating = user_item_matrix.loc[sim_user, item]\n                if rating > 0:\n                    numerator += sim_scores[i] * rating\n                    denominator += sim_scores[i]\n            if denominator > 0:\n                predicted_ratings[item] = numerator / denominator\n\n    # Return top 5 recommendations\n    return sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)[:]\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 64
    },
    {
      "id": "c7fa76ca-7547-4268-a238-6d2b3b44dff3",
      "cell_type": "code",
      "source": "def train_ubcf(ratings_df):\n    \"\"\"\n    Prepares UBCF data structures.\n\n    Returns:\n        user_item_matrix: user-item rating matrix\n        similarity_df: cosine similarity between users (DataFrame)\n    \"\"\"\n    user_item_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n    user_similarity = cosine_similarity(user_item_matrix)\n    similarity_df = pd.DataFrame(user_similarity,\n                                 index=user_item_matrix.index,\n                                 columns=user_item_matrix.index)\n    return user_item_matrix, similarity_df\n\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 65
    },
    {
      "id": "2665754a-2fee-46e0-8787-906031d34cf4",
      "cell_type": "code",
      "source": "def recommend_ubcf(user_id, user_item_matrix, similarity_df, ratings_df, k=5, top_n=10):\n    \"\"\"\n    Recommend top-N items for a user using UBCF.\n\n    Args:\n        user_id (int): Target user\n        user_item_matrix (DataFrame): user-item matrix from train_ubcf\n        similarity_df (DataFrame): cosine similarity between users\n        ratings_df (DataFrame): raw ratings data\n        k (int): Number of neighbors\n        top_n (int): Number of recommendations to return\n\n    Returns:\n        List of (item_id, predicted_rating)\n    \"\"\"\n    if user_id not in user_item_matrix.index:\n        return []\n\n    # Get k most similar users\n    similar_users = similarity_df[user_id].drop(user_id).nlargest(k)\n    sim_scores = similar_users.values\n    sim_user_ids = similar_users.index\n\n    # Items user has already rated\n    seen_items = set(ratings_df[ratings_df['userId'] == user_id]['movieId'])\n\n    predictions = {}\n    for item in user_item_matrix.columns:\n        if item in seen_items:\n            continue\n\n        numerator, denominator = 0.0, 0.0\n        for i, sim_user in enumerate(sim_user_ids):\n            rating = user_item_matrix.loc[sim_user, item]\n            if rating > 0:\n                numerator += sim_scores[i] * rating\n                denominator += sim_scores[i]\n        if denominator > 0:\n            predictions[item] = numerator / denominator\n\n    return sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:top_n]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 66
    },
    {
      "id": "d30107df-2429-446d-8c52-708db0452700",
      "cell_type": "code",
      "source": "user_item_matrix, similarity_df = train_ubcf(original_ratings_df)\n\n# Use it for a user\nuser_id = 5\nrecs = recommend_ubcf(user_id, user_item_matrix, similarity_df, original_ratings_df, k=10, top_n=10)\nprint(\"Recommendations for user 5:\", recs)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Recommendations for user 5: [(25, np.float64(5.0)), (151, np.float64(5.0)), (362, np.float64(5.0)), (780, np.float64(5.0)), (168, np.float64(4.999999999999999)), (218, np.float64(4.999999999999999)), (222, np.float64(4.999999999999999)), (249, np.float64(4.999999999999999)), (280, np.float64(4.999999999999999)), (293, np.float64(4.999999999999999))]\n"
        }
      ],
      "execution_count": 67
    },
    {
      "id": "eb1c90a9-4f09-4c80-b6a9-5067f38b5a5e",
      "cell_type": "markdown",
      "source": "#### Recommender 2: FunkSVD (Matrix Factorization using Stochastic Gradient Descent (SGD))",
      "metadata": {}
    },
    {
      "id": "fa26fb48-0bfe-460e-a78b-9144840ca3ff",
      "cell_type": "markdown",
      "source": "FunkSVD learns latent features for users and items based on historical ratings. It uses stochastic gradient descent (SGD) to learn these features by minimizing the error between actual and predicted ratings.",
      "metadata": {}
    },
    {
      "id": "395f3836-439a-4f70-af2f-6d4b13e320ea",
      "cell_type": "code",
      "source": "def funk_svd(ratings_df, K=20, epochs=20, alpha=0.005, beta=0.02, verbose=True):\n    \"\"\"\n    ratings_df: DataFrame with user_id, item_id, rating\n    K: number of latent factors\n    alpha: learning rate\n    beta: regularization\n    \"\"\"\n    num_users = ratings_df['userId'].max()\n    num_items = ratings_df['movieId'].max()\n\n    # Initialize latent factor matrices\n    P = np.random.normal(scale=1./K, size=(num_users, K))  # user latent features\n    Q = np.random.normal(scale=1./K, size=(num_items, K))  # item latent features\n\n    ratings = ratings_df[['userId', 'movieId', 'rating']].values\n\n    for epoch in range(epochs):\n        np.random.shuffle(ratings)\n        total_loss = 0\n\n        for user, item, rating in ratings:\n            u = int(user) - 1\n            i = int(item) - 1\n\n            pred = np.dot(P[u], Q[i])\n            err = int(rating) - pred\n\n            # Update latent features\n            P[u] += alpha * (err * Q[i] - beta * P[u])\n            Q[i] += alpha * (err * P[u] - beta * Q[i])\n\n            total_loss += err ** 2\n\n        if verbose:\n            rmse = np.sqrt(total_loss / len(ratings))\n            print(f\"Epoch {epoch+1}/{epochs}, RMSE: {rmse:.4f}\")\n\n    return P, Q",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "id": "10698ade-f3fc-431a-a29c-ac36d3295b90",
      "cell_type": "code",
      "source": "P, Q = funk_svd(original_ratings_df, K=20, epochs=25, alpha=0.005, beta=0.02)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch 1/25, RMSE: 3.5228\nEpoch 2/25, RMSE: 3.4287\nEpoch 3/25, RMSE: 2.5364\nEpoch 4/25, RMSE: 1.7990\nEpoch 5/25, RMSE: 1.4830\nEpoch 6/25, RMSE: 1.3116\nEpoch 7/25, RMSE: 1.2029\nEpoch 8/25, RMSE: 1.1273\nEpoch 9/25, RMSE: 1.0715\nEpoch 10/25, RMSE: 1.0281\nEpoch 11/25, RMSE: 0.9924\nEpoch 12/25, RMSE: 0.9628\nEpoch 13/25, RMSE: 0.9372\nEpoch 14/25, RMSE: 0.9148\nEpoch 15/25, RMSE: 0.8942\nEpoch 16/25, RMSE: 0.8762\nEpoch 17/25, RMSE: 0.8594\nEpoch 18/25, RMSE: 0.8444\nEpoch 19/25, RMSE: 0.8301\nEpoch 20/25, RMSE: 0.8166\nEpoch 21/25, RMSE: 0.8040\nEpoch 22/25, RMSE: 0.7917\nEpoch 23/25, RMSE: 0.7799\nEpoch 24/25, RMSE: 0.7686\nEpoch 25/25, RMSE: 0.7576\n"
        }
      ],
      "execution_count": 24
    },
    {
      "id": "2fcca5b7-fcb1-40e6-9d76-1e7cbce3c2fc",
      "cell_type": "code",
      "source": "def predict(user_id, item_id, P, Q):\n    return np.dot(P[user_id - 1], Q[item_id - 1])\n\n# Example\nprint(f\"Predicted rating for user 5 on movie 50: {predict(10, 25, P, Q):.2f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Predicted rating for user 5 on movie 50: 2.58\n"
        }
      ],
      "execution_count": 27
    },
    {
      "id": "673d472e-b542-4cfb-82bb-a49f05d858b5",
      "cell_type": "code",
      "source": "def predict_all_items_for_user(user_id, P, Q, seen_items=None, top_n=10):\n    \"\"\"\n    Predict all item ratings for a user using FunkSVD.\n\n    Args:\n        user_id (int): The ID of the user (1-based)\n        P (np.ndarray): User latent matrix\n        Q (np.ndarray): Item latent matrix\n        seen_items (list or set): Item IDs the user has already rated (1-based)\n        top_n (int): Return top-N predictions\n\n    Returns:\n        List of tuples (item_id, predicted_rating), sorted by rating descending\n    \"\"\"\n    u = user_id - 1  # Convert to 0-based index\n    user_vector = P[u]\n\n    # Predict scores for all items\n    scores = np.dot(Q, user_vector)  # Q is items x K, user_vector is (K,)\n    \n    item_ids = np.arange(1, Q.shape[0] + 1)  # item IDs are 1-based\n\n    # Optionally filter out already-seen items\n    if seen_items:\n        seen_items = set(seen_items)\n        predictions = [(item_id, score) for item_id, score in zip(item_ids, scores) if item_id not in seen_items]\n    else:\n        predictions = list(zip(item_ids, scores))\n\n    # Return top-N sorted\n    predictions.sort(key=lambda x: x[1], reverse=True)\n    return predictions[:top_n]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "id": "8f379b48-49b0-4c67-9f6b-aa4e9ab91e9c",
      "cell_type": "markdown",
      "source": "### Metric\tMeasures\n**Novelty** is a measure of recommending less popular items. <br> **Diversity** is how different the recommended items are from each other.<br> **Serendipity** is recommending unexpected items that are still relevant.",
      "metadata": {}
    },
    {
      "id": "3ebd7e62-f207-4224-825c-16d755770701",
      "cell_type": "code",
      "source": "def get_item_popularity(df):\n    item_counts = Counter(df['movieId'])\n    return dict(item_counts)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "id": "cc4d7038-b953-4bf3-a59e-453be4e9d9c5",
      "cell_type": "markdown",
      "source": "#### Novelty\n**Novelty score** = average popularity of recommended items <br>\n**Higher score** = less novel <br>\n**Lower score** = more novel",
      "metadata": {}
    },
    {
      "id": "d7b60eba-7b16-4105-88d3-66e05f94fe89",
      "cell_type": "code",
      "source": "def novelty(recommended_items, item_popularity):\n    \"\"\"\n    recommended_items: list of item IDs\n    item_popularity: dict of item_id -> count\n    \"\"\"\n    popularity_scores = [item_popularity.get(item, 0) for item in recommended_items]\n    return np.mean(popularity_scores)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "id": "516eedcc-120c-4577-9b26-c42ef5307617",
      "cell_type": "markdown",
      "source": "#### Diversity (Pairwise dissimilarity between items)\nAssume no content-based info, we’ll use Jaccard on user sets (collaborative-only diversity):",
      "metadata": {}
    },
    {
      "id": "52f782f9-11a2-4c57-9c48-51888419d429",
      "cell_type": "code",
      "source": "def jaccard_similarity(set1, set2):\n    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0\n\ndef diversity(recommended_items, user_item_dict):\n    \"\"\"\n    recommended_items: list of item IDs\n    user_item_dict: dict of item_id -> set of user_ids who interacted\n    \"\"\"\n    pairs = [(i, j) for idx, i in enumerate(recommended_items) \n                     for j in recommended_items[idx + 1:]]\n    diversities = []\n    for i, j in pairs:\n        users_i = user_item_dict.get(i, set())\n        users_j = user_item_dict.get(j, set())\n        sim = jaccard_similarity(users_i, users_j)\n        diversities.append(1 - sim)\n    return np.mean(diversities) if diversities else 0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "id": "0de7370a-64cc-45a0-aaa4-42b14e8410d1",
      "cell_type": "markdown",
      "source": "#### Serendipity\nAn item is serendipitous if:<br>\nIt's relevant (user actually liked it), and <br> \nIt’s unexpected (not in popular items)",
      "metadata": {}
    },
    {
      "id": "fb6a744a-adbf-4519-9bda-7d546b23adfe",
      "cell_type": "code",
      "source": "def serendipity(user_id, recommendations, relevant_items, popular_items):\n    count = 0\n    for item in recommendations:\n        if item in relevant_items and item not in popular_items:\n            count += 1\n    return count / len(recommendations) if recommendations else 0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 42
    },
    {
      "id": "28c31232-24c9-4a47-b2b8-1f361013b3c8",
      "cell_type": "markdown",
      "source": "#### Evaluation ",
      "metadata": {}
    },
    {
      "id": "ab5265ca-5b17-439a-a5d0-9b311592940f",
      "cell_type": "code",
      "source": "def evaluate_recommender(model_name, recommend_fn, df, P=None, Q=None):\n    item_popularity = get_item_popularity(df)\n    user_item_dict = df.groupby('movieId')['userId'].apply(set).to_dict()\n\n    top_popular_items = set([item for item, count in Counter(df['movieId']).most_common(50)])\n\n    users = df['userId'].unique()[:100]  # Test on a small subset\n    novelty_scores = []\n    diversity_scores = []\n    serendipity_scores = []\n\n    for user_id in users:\n        seen_items = df[df['userId'] == user_id]['movieId'].tolist()\n        relevant_items = set([item for item in seen_items if df[(df['userId'] == user_id) & (df['movieId'] == item)]['rating'].mean() >= 4])\n\n        # Get recommendations\n        if model_name == 'FunkSVD':\n            recs = predict_all_items_for_user(user_id, P, Q, seen_items, top_n=10)\n            rec_items = [item for item, _ in recs]\n        else:  # UBCF\n            rec_items = [item for item, _ in recommend_fn(user_id)]\n\n        # Evaluate\n        novelty_scores.append(novelty(rec_items, item_popularity))\n        diversity_scores.append(diversity(rec_items, user_item_dict))\n        serendipity_scores.append(serendipity(user_id, rec_items, relevant_items, top_popular_items))\n\n    return {\n        'novelty': np.mean(novelty_scores),\n        'diversity': np.mean(diversity_scores),\n        'serendipity': np.mean(serendipity_scores),\n    }",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 139
    },
    {
      "id": "14247448-246f-4d4c-b2d0-8ae7495d8759",
      "cell_type": "code",
      "source": "def ubcf_recommend_wrapper(user_id):\n    return recommend_ubcf(user_id, user_item_matrix, similarity_df, original_ratings_df, k=10, top_n=10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 74
    },
    {
      "id": "c1ebad54-23be-424c-a4fd-16f48acc536d",
      "cell_type": "code",
      "source": "ubcf_metrics = evaluate_recommender('UBCF', recommend_fn=ubcf_recommend_wrapper, df=original_ratings_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "650eb316-3e9f-4271-bb98-f0192d0e4eb1",
      "cell_type": "code",
      "source": "funk_metrics = evaluate_recommender('FunkSVD', recommend_fn=None, df=original_ratings_df, P=P, Q=Q)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 79
    },
    {
      "id": "95de4d77-567e-4795-a856-120d39ac6e3c",
      "cell_type": "code",
      "source": "print(\"UBCF Metrics:\", ubcf_metrics)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "UBCF Metrics: {'novelty': np.float64(57.873999999999995), 'diversity': np.float64(0.8659564624739196), 'serendipity': np.float64(0.0)}\n"
        }
      ],
      "execution_count": 77
    },
    {
      "id": "9b98289e-459d-443e-a84c-a08018c6221b",
      "cell_type": "code",
      "source": "print(\"FunkSVD Metrics:\", funk_metrics)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "FunkSVD Metrics: {'novelty': np.float64(58.09299999999999), 'diversity': np.float64(0.9211369206904918), 'serendipity': np.float64(0.0)}\n"
        }
      ],
      "execution_count": 80
    },
    {
      "id": "e5da680b-8764-4d27-bf28-35e4153f880c",
      "cell_type": "markdown",
      "source": "### Comparing Metrics:\n\nOur FunkSVD model has slightly higher **novelty** score, meaning more popular items are being recommended, but slightly higher **diversity** meaning there is more dissimilarity among recommended items.\n\nOur UBCF model has slightly lower **novelty** score, meaning slightly more obscure items are being recommended, but it has slightly lower **diversity** meaning there is more similarity among the recommended items.\n\nBoth models have the same extremly low **serendipity**. I think this is because both are tending to recommend popular movies, we're only returning the top 10 recommendations and all those 10 are all seen or popular.\n\nI would prefer the FunkSVD model, for more varied content in my top 10 list, at the cost of the movies being slightly more well known. ",
      "metadata": {}
    },
    {
      "id": "15737bb3-fbd7-49cf-883b-0cc9021cec31",
      "cell_type": "markdown",
      "source": "### 2. Implement support for at least one business or user experience goal such as increased serendipity, novelty, or diversity.",
      "metadata": {}
    },
    {
      "id": "66caeaa8-5a9d-4328-9474-7743c2a0d8d1",
      "cell_type": "markdown",
      "source": "### Increasing Serendipity\nWe'll rerank a candidate recommendation list (e.g., from FunkSVD or UBCF) by boosting items that are:\n- Unpopular (low global popularity)\n- Predicted to be relevant (predicted rating is high)",
      "metadata": {}
    },
    {
      "id": "58f1c983-4315-4d61-bad0-2e90c42db848",
      "cell_type": "code",
      "source": "def rerank_for_serendipity(user_id, recommendations, ratings_df, popularity_weight=0.6):\n    \"\"\"\n    Rerank items to increase serendipity (favoring less popular but relevant items).\n\n    Args:\n        user_id (int): The user to recommend to\n        recommendations: List of (item_id, predicted_rating)\n        ratings_df: Full ratings DataFrame\n        popularity_weight (float): [0,1] controls tradeoff. Higher = more serendipity\n\n    Returns:\n        List of (item_id, adjusted_score)\n    \"\"\"\n    # Compute item popularity\n    item_counts = Counter(ratings_df['movieId'])\n    max_pop = max(item_counts.values())\n    \n    reranked = []\n    for item_id, predicted_rating in recommendations:\n        popularity = item_counts.get(item_id, 0) / max_pop  # normalize to [0,1]\n        unexpectedness = 1 - popularity                     # higher = less popular\n        adjusted_score = (1 - popularity_weight) * predicted_rating + popularity_weight * unexpectedness\n        reranked.append((item_id, adjusted_score))\n\n    return sorted(reranked, key=lambda x: x[1], reverse=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 148
    },
    {
      "id": "492ad413-c553-4565-8825-8902c1719710",
      "cell_type": "code",
      "source": "def evaluate_recommender_serendipity(model_name, recommend_fn, df, P=None, Q=None):\n    item_popularity = get_item_popularity(df)\n    user_item_dict = df.groupby('movieId')['userId'].apply(set).to_dict()\n\n    top_popular_items = set([item for item, count in Counter(df['movieId']).most_common(5)])\n\n    users = df['userId'].unique()[0:100]  # Test on a small subset\n    novelty_scores = []\n    diversity_scores = []\n    serendipity_scores = []\n\n    for user_id in users:\n        seen_items = df[df['userId'] == user_id]['movieId'].tolist()\n        relevant_items = set([item for item in seen_items if df[(df['userId'] == user_id) & (df['movieId'] == item)]['rating'].mean() >= 3])\n\n        # Get recommendations\n        if model_name == 'FunkSVD':\n            recs = predict_all_items_for_user(user_id, P, Q, seen_items, top_n=50)\n            reranked_recs = rerank_for_serendipity(user_id, recs, df, popularity_weight=0.6)\n            rec_items = [item for item, _ in reranked_recs[:10]]\n        else:  # UBCF\n            rec_items = [item for item, _ in ubcf_with_serendipity(user_id)]\n\n\n        # Evaluate\n        novelty_scores.append(novelty(rec_items, item_popularity))\n        diversity_scores.append(diversity(rec_items, user_item_dict))\n        serendipity_scores.append(serendipity(user_id, rec_items, relevant_items, top_popular_items))\n\n    return {\n        'novelty': np.mean(novelty_scores),\n        'diversity': np.mean(diversity_scores),\n        'serendipity': np.mean(serendipity_scores),\n    }",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 155
    },
    {
      "id": "d6da4f1a-aeba-43e4-9976-daa20a92760e",
      "cell_type": "code",
      "source": "def ubcf_with_serendipity(user_id):\n    # Step 1: Get original recommendations from UBCF\n    recs = recommend_ubcf(user_id, user_item_matrix, similarity_df, original_ratings_df, k=10, top_n=50)\n\n    # Step 2: Apply serendipity reranking\n    reranked_recs = rerank_for_serendipity(user_id, recs, original_ratings_df, popularity_weight=0.6)\n\n    # Step 3: Return top-N\n    return reranked_recs[:10]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 156
    },
    {
      "id": "658e090c-4312-4608-8840-88db68a290d7",
      "cell_type": "code",
      "source": "ubcf_metrics_serendipity = evaluate_recommender_serendipity('UBCF', recommend_fn=ubcf_with_serendipity, df=original_ratings_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 157
    },
    {
      "id": "bf821ad0-54fb-4287-8ad7-976b324c4f95",
      "cell_type": "code",
      "source": "funk_metrics_serendipity = evaluate_recommender_serendipity('FunkSVD', recommend_fn=None, df=original_ratings_df, P=P, Q=Q) ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 151
    },
    {
      "id": "b0144b21-4b78-4151-9956-a40291ccf8be",
      "cell_type": "code",
      "source": "print(\"UBCF Metrics:\", ubcf_metrics_serendipity)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "UBCF Metrics: {'novelty': np.float64(16.692), 'diversity': np.float64(0.885276672185159), 'serendipity': np.float64(0.0)}\n"
        }
      ],
      "execution_count": 158
    },
    {
      "id": "807efdc0-d659-4d73-b0fc-d431c4a588a6",
      "cell_type": "code",
      "source": "print(\"FunkSVD Metrics:\", funk_metrics_serendipity)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "FunkSVD Metrics: {'novelty': np.float64(5.1979999999999995), 'diversity': np.float64(0.968821842523899), 'serendipity': np.float64(0.0)}\n"
        }
      ],
      "execution_count": 159
    },
    {
      "id": "3d5fc819-7343-472a-875a-14902eac5d77",
      "cell_type": "markdown",
      "source": "### I made some changes to try to increase serendipity:\n-  used rerank_for_serendipity to try to boost items that were less popular but still relevant\n-  changed relevant items rating mean cut off to 3, so its not so strict as to what the interested items should be for users\n-  changed both UBCF and FunkSVD to look at the top 50 for each user, and then after cut to top 10 using the serendipitiously reranked list\n-  changed the popular list to just look at the 5 most common movies\n    \nSerendiptity still has stayed at 0 after these changes. Im unsure what isn't working as intended.\n\nPossible problems is that all the relevant items are popular? This is unlikely as the popular list is only the 5 most popular movies. ",
      "metadata": {}
    },
    {
      "id": "4a542207-370c-4ddf-a686-f1411c7db32e",
      "cell_type": "markdown",
      "source": "### 3. Compare and report on any change in accuracy before and after you’ve made the change in #2.",
      "metadata": {}
    },
    {
      "id": "5213b498-e7f9-423f-bb69-cf1a53f5aedb",
      "cell_type": "markdown",
      "source": "### Looking at Novelty and Diversity in this \"Serendipitious Model\":\n- **Novelty** has massively dropped after these changes meaning obscure or less popular items are being recommended, **Diversity** has slightly increased for both suggesting there are now more variations among  the recommended items\n- It's possible with these changes, we are now just trending towards suggesting bad movies, as we strive for less popular movies, we have to pull from the bottom of the barrel. Its also possible that the user experience will feel more random, and less personalized to a user's tastes. This is a indie maximalist approach to movie recommendation, probably most suitable for a buzzfeed type \"10 Movies You've Never Heard Of!!!\" list\n- I think I might prefer the UBCF model this time as its suggesting slightly more popular movies, while still keeping a good amount of diversity on the list",
      "metadata": {}
    },
    {
      "id": "4eacad36-f88a-4b01-b8bd-13e48ab0c8df",
      "cell_type": "code",
      "source": "print(\"UBCF Metrics:\", ubcf_metrics)\nprint(\"UBCF serendipity Metrics:\", ubcf_metrics_serendipity)\nprint(\"FunkSVD Metrics:\", funk_metrics)\nprint(\"FunkSVD serendipity Metrics:\", funk_metrics_serendipity)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "UBCF Metrics: {'novelty': np.float64(57.873999999999995), 'diversity': np.float64(0.8659564624739196), 'serendipity': np.float64(0.0)}\nUBCF serendipity Metrics: {'novelty': np.float64(16.692), 'diversity': np.float64(0.885276672185159), 'serendipity': np.float64(0.0)}\nFunkSVD Metrics: {'novelty': np.float64(58.09299999999999), 'diversity': np.float64(0.9211369206904918), 'serendipity': np.float64(0.0)}\nFunkSVD serendipity Metrics: {'novelty': np.float64(5.1979999999999995), 'diversity': np.float64(0.968821842523899), 'serendipity': np.float64(0.0)}\n"
        }
      ],
      "execution_count": 161
    },
    {
      "id": "0a8539e3-3891-4217-b288-93a33df3d18c",
      "cell_type": "markdown",
      "source": "### 4. Conclusion",
      "metadata": {}
    },
    {
      "id": "63a95789-c867-4f06-a13f-29d962ae1842",
      "cell_type": "markdown",
      "source": "I looked at the MovieLends 100k dataset. I implemented both a User-Based Collaborative Filtering (UBCF) and FunkSVD recommender system. I did away with traditional accuracy meteics like RMSE this time, favoring serendipity, novelty, and diversity as methods of measuring out user's satification with our recommendations. \n\nThe FunkSVD model has slightly higher novelty score, meaning more popular items are being recommended, but slightly higher diversity meaning there is more dissimilarity among recommended items. Our UBCF model has slightly lower novelty score, meaning slightly more obscure items are being recommended, but it has slightly lower diversity meaning there is more similarity among the recommended items. I would prefer the FunkSVD model, for more varied content in my top 10 list, at the cost of the movies being slightly more well known.\n\nWe tried to increase serendiptity by adding a popularity_weight hoping to boost boosting items that are unpopular (low global popularity) but still predicted to be relevant (predicted rating is high). Novelty has massively dropped after these changes meaning obscure or less popular items are being recommended, Diversity has slightly increased for both suggesting there are now more variations among the recommended items. Unfortuately, its possible with these changes, we are now just trending towards suggesting bad movies, as we strive for less popular movies, we have to pull from the bottom of the barrel.\n\n",
      "metadata": {}
    },
    {
      "id": "f90a6802-bb6a-4967-8b77-ad3e6ee339f9",
      "cell_type": "markdown",
      "source": "### Online Evaluation Experiments",
      "metadata": {}
    },
    {
      "id": "cfacbb76-1d7f-4749-bcfc-809f9c9ec6b6",
      "cell_type": "markdown",
      "source": "##### A/B Testing with Recommender Variants\n- Compare our two recommenders (UBCF vs. FunkSVD) in live usage\n- Randomly assigne users to \"buckets\" (Group A gets UBCF, Group B gets FunkSVD)\n\n##### Recommendation Conversion Rate / Watch Rate \n- Did the user actually watch the item after we recommended it? We can calculate Watch rate\n\n##### Serendipity Perception\n- Track how much variety or surprise users actually experience and enjoy\n- See how often users engage with our non-popular recommendations\n- Ask them survey-based feedback: “Was this recommendation surprising and good?”",
      "metadata": {}
    },
    {
      "id": "c6dc7e27-b65b-4d79-b08c-087dfa27ba5b",
      "cell_type": "markdown",
      "source": "### Design online evaluation environment\n\n##### 1. Frontend Logging System\n- Log every recommendation shown to each user\n- Log interactions: clicks, skips, watch duration, etc.\n\n##### 2. A/B Testing Framework\n- Randomly assign users to experimental groups and ensure users stick with their assigned group:\n- Group A: FunkSVD\n- Group B: Standard UBCF\n- Group C: Serendipitious models\n\n##### 3. Backend Pipeline\n- Store logs in a database or data warehouse\n- Periodically calculate online metrics (watch rate, CTR, etc.)",
      "metadata": {}
    },
    {
      "id": "983c0c80-65fb-4a4f-bb84-2cb2d5dacb4b",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}